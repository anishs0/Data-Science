{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a57a084",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7669395",
   "metadata": {},
   "source": [
    "A machine learning hypothesis is not simply determined by the learning algorithm but also by its hyperparameters (the parameters of the algorithm that have to be fixed prior, and which cannot be learned during the training process) and the selection of variables to be used to achieve the best learned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478fa395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn import svm\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "h = svm.SVC() #plain SVC\n",
    "hp = svm.SVC(probability=True, random_state=1) #enhanced SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450fd589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.02 s ± 762 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "SVC(C=10, gamma=0.001)\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.9810738671632526\n"
     ]
    }
   ],
   "source": [
    "#GridSearchCV will automatically search for the best parameters according to a search schedule and score the results\n",
    "# with respect to a predefined or custom scoring function\n",
    "from sklearn import model_selection\n",
    "search_grid = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "               {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
    "                'kernel': ['rbf']},\n",
    "          ]\n",
    "scorer = 'accuracy'\n",
    "search_func = model_selection.GridSearchCV(estimator=h,  \n",
    "                            param_grid=search_grid, scoring=scorer, \n",
    "                            n_jobs=-1, refit=True, cv=10)\n",
    "#n_jobs =-1 use all the processors available on the computer\n",
    "#refit =true so that function fits the whole training set\n",
    "%timeit search_func.fit(X,y) #to know how much time it will take to complete entire procedure\n",
    "print (search_func.best_estimator_)\n",
    "print (search_func.best_params_)\n",
    "print (search_func.best_score_)\n",
    "#need to apply the search_funct.predict() method to fresh data in order to obtain new predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e56f3",
   "metadata": {},
   "source": [
    "## Building custom scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a3380b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.15958263353486224\n",
      "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" For classification, there are five measures available (accuracy, AUC, precision, recall, and f1-score),\n",
    "and for regression, there are three (R2, MAE, and MSE)\"\"\"\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "Log_Loss = make_scorer(log_loss, \n",
    "                        greater_is_better=False, \n",
    "                        needs_proba=True)\n",
    "search_func = model_selection.GridSearchCV(estimator=hp, \n",
    "                         param_grid=search_grid, scoring=Log_Loss, \n",
    "                           n_jobs=-1, refit=True, cv=3)\n",
    "search_func.fit(X,y)\n",
    "#hyperparameters are optimized for log loss, not for accuracy\n",
    "print (search_func.best_score_)\n",
    "print (search_func.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b97135",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61479b6",
   "metadata": {},
   "source": [
    "It simplifies high-dimensional structures by choosing the most predictive set of variables\n",
    "Feature selection Methods:\n",
    "Selection based on the variance\n",
    "Univariate selection\n",
    "Recursive elimination\n",
    "Randomized logistic regression/stability selection\n",
    "L1-based feature selection\n",
    "Tree-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17abecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
